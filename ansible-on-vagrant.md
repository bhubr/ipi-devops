# IMDW280/DevOps - Ansible

## Introduction

### DevOps

Le terme DevOps est issu de la contraction de _dev_ (_development_) et _ops_ (_operations_ = ce qui rel√®ve de l'administration syst√®me et r√©seau).

C'est un terme aux multiples facettes, qui peut d√©signer :

* Une philosophie, une approche, un mouvement, visant √† faire √©voluer la fa√ßon dont on d√©veloppe et met en production des applications,
* Un m√©tier (_ing√©nieur DevOps_)

Une d√©finition assez commune est que le DevOps vise √† d√©cloisonner, dans une organisation, les aspects _dev_ et _ops_, et √† faire en sorte que les protagonistes des deux c√¥t√©s travaillent ensemble plus efficacement.

Traditionnellement, ces m√©tiers ob√©issent en effet √† des contraintes qu'on pourrait qualifier d'antagonistes :

* M√ªs par des imp√©ratifs d'innovation et de comp√©titivit√©, les d√©veloppeurs mettent √† jour leurs application, pour b√©n√©ficier des nouvelles versions de leurs langages et frameworks. Ils adoptent rapidement des technologies √©mergentes.
* Garants de la fiabilit√© et la stabilit√© des infrastructures, les administrateurs peuvent avoir une approche plus conservatrice : est-ce que telle nouvelle technologie ne va pas amener de nouvelles probl√©matiques (notamment de s√©curit√©) ?

L'approche DevOps cherche √† "r√©concilier" l'innovation permanente et la fiabilit√©.

Dans la foul√©e du mouvement Agile, le mouvement DevOps a donn√© naissance √† de nombreux outils, qui changent la fa√ßon dont on d√©veloppe et met en production des applications.

### Du besoin d'automatisation

Les architectes r√©seau con√ßoivent des infrastructures, et les administrateurs syst√®me et r√©seau les exploitent et les maintiennent (ces r√¥les peuvent √™tre fusionn√©s dans des organisations de petite taille).

Prenons l'exemple d'un administrateur charg√© de mettre en ligne une application web, de fa√ßon √† la rendre accessible sur Internet, ou sur l'Intranet d'une entreprise.

Dans une approche traditionnelle, il doit installer un syst√®me d'exploitation sur une machine (physique ou virtuelle), puis diff√©rents paquets logiciels requis pour faire fonctionner l'application.

Si on prend l'exemple d'une application "full-stack" JavaScript, avec un backend Node.js reli√© √† une base de donn√©es MySQL, et un frontend Angular, il ou elle devra :

* Installer Node.js,
* Installer un serveur web qui redirigera le trafic vers l'application Node.js,
* Installer le serveur MySQL, cr√©er une base de donn√©es pour l'application, configurer un compte utilisateur avec des droits sur cette base de donn√©es,
* R√©cup√©rer les applications backend et frontend depuis des d√©p√¥ts Git (h√©berg√©s sur GitHub, BitBucket, GitLab, etc.),
* √âventuellement "builder" les applications,
* Faire en sorte que l'application Node.js red√©marre automatiquement si elle plante,
* Mettre en place des outils de monitoring, afin d'√™tre averti.e d'incidents,
* Mettre en place des sauvegardes automatiques,
* G√©rer le renouvellement des certificats pour le HTTPS,
* etc. !

Toutes ces op√©rations peuvent √™tre accomplies via des commandes shell, √† saisir dans un certain ordre.

Si on effectue cela manuellement, c'est √† la fois tr√®s chronophage et sujet √† des erreurs humaines : m√™me si la proc√©dure est scrupuleusement document√©e, personne n'est √† l'abri de l'oubli d'une √©tape.

Une approche possible est d'utiliser des _scripts shell_ pour automatiser, dans une certaine mesure, tout cela. C'est une approche pertinente, mais qui peut poser des probl√®mes : comment faire si on doit relancer une partie seulement de la proc√©dure ? Est-ce que le fait de lancer plusieurs fois le m√™me script aboutira toujours au m√™me r√©sultat ?

Ansible va permettre de r√©pondre √† cette probl√©matique d'automatisation, de fa√ßon fiable et efficace.

> Gardez √† l'esprit qu'Ansible n'est pas le seul outil permettant de r√©pondre √† cette probl√©matique. Des outils tels que Docker offrent une autre approche. Il ne s'agit cependant pas de les opposer, car ils peuvent √™tre compl√©mentaires.

### Qu'est-ce qu'Ansible ?

Ansible est un outil permettant d'automatiser toutes sortes de t√¢ches sur des serveurs.

√Ä partir d'un noeud appel√© _control node_, on contr√¥le des serveurs appel√©s _managed nodes_.

On va, par exemple, pouvoir lancer la m√™me commande sur tous les _managed nodes_, √† partir du _control node_.

L'int√©r√™t est d'automatiser la configuration de serveurs, ce qui offre un gain de temps d'autant plus appr√©ciable que la "flotte" de machines √† configurer est cons√©quente.

## Installer et utiliser Ansible

### Ansible sous Windows ?

Ansible est un outil orient√© Unix. De fait, le _control node_ doit imp√©rativement √™tre un syst√®me Un*x ("Unix-like") tel que Linux, FreeBSD, MacOS, etc. Le portage du contr√¥leur Ansible sous Windows est, de l'aveu de ses d√©veloppeurs, une t√¢che colossale, qui ne sera vraisemblablement pas r√©alis√©e avant quelques ann√©es.

On peut cependant utiliser Ansible sous Windows :

* soit en utilisant le sous-syst√®me Linux pour Windows [WSL2](https://docs.microsoft.com/fr-fr/windows/wsl/install), qui servira de _control node_, et au moins une ou plusieurs machine(s) virtuelle(s) pour le(s) _managed node(s)_.
* soit uniquement dans des machines virtuelles, le _control node_ √©tant aussi une VM.

### VirtualBox ?

Plusieurs logiciels de virtualisation sont disponibles sur le march√© : VMWare, VirtualBox, etc.

VMWare Player (la version gratuite), souffre de limitations, notamment concernant la mise en r√©seau de machines virtuelles. VirtualBox est gratuit et moins limit√©.

On pourrait donc l'utiliser, et pr√©parer manuellement des machines virtuelles. Une telle entreprise implique entre autres de param√©trer :

* la quantit√© de RAM
* un disque dur virtuel
* une ou plusieurs interfaces r√©seau

Il faut √©galement t√©l√©charger une "image ISO" d'une distribution Linux (Debian, CentOS, openSUSE, etc.) qu'il faudra installer sur le disque dur virtuel de la VM, comme on le ferait sur une machine physique.

Cette proc√©dure est assez rapide quand on en a l'habitude, et une fois la premi√®re VM ainsi configur√©e, il est facile de la cloner pour √©viter la duplication d'efforts. Cependant, il est tout aussi facile de faire une erreur au cours de la proc√©dure, quand on d√©bute !

> :warning: **Ajout** : pour certain.e.s d'entre vous, Vagrant, d√©crit dans la section suivante, a pos√© des probl√®mes, aussi une [alternative bas√©e sur VirtualBox](https://github.com/bhubr/ipi-devops/blob/master/ansible-on-virtualbox.md) vous est propos√©e.

### Vagrant

Vagrant permet de configurer tr√®s facilement des machines virtuelles, √† partir d'un fichier de configuration, le `Vagrantfile`.

Vagrant repose par d√©faut sur VirtualBox, mais offre, entre autres avantages, la simplicit√© et rapidit√© de mise en oeuvre : au lieu de devoir installer soi-m√™me un OS dans une VM, on peut d√©marrer une VM √† partir d'une "box" pr√©-configur√©e, t√©l√©charg√©e automatiquement par Vagrant depuis un d√©p√¥t central.

## Installation et configuration de Vagrant

* T√©l√©charger la version **64-bit** depuis [la page officielle de t√©l√©chargements](https://www.vagrantup.com/downloads)
* Lancer l'installeur (5 √©tapes, garder les choix propos√©s par d√©faut)

### Premier test de Vagrant

Juste pour verifier que tout fonctionne correctement !

* Lancer PowerShell
* Se rendre dans Documents : `cd ~\Documents`
* Creer un dossier `DevOps` : `mkdir DevOps`
* Puis creer un sous-dossier `TestDebian` : `mkdir DevOps\TestDebian`
* Aller sous ce dossier : `cd DevOps\TestDebian`
* Initialiser une machine virtuelle. On a choisi une Debian 64-bits (version 11, au nom de code "bullseye") : `vagrant init debian/bullseye64`
* La commande pr√©c√©dente a g√©n√©r√© un fichier `Vagrantfile`, qu'on va garder tel quel
* Puis demarrer la VM : `vagrant up` (devrait donner l'affichage assez verbeux ci-dessous)
* Puis se connecter dans la VM : `vagrant ssh`
* Si tout a bien fonctionn√© : quitter la session SSH en saisissant `logout`
* Arr√™ter la VM : `vagrant halt`
* **Garder PowerShell ouvert** (il va nous resservir !)

Sortie obtenue en lan√ßant `vagrant up` (notez que la box `debian/bullseye64` est t√©l√©charg√©e depuis le d√©p√¥t Vagrant Cloud) :

```
Bringing machine 'default' up with 'virtualbox' provider...
==> default: Box 'debian/bullseye64' could not be found. Attempting to find and install...
    default: Box Provider: virtualbox
    default: Box Version: >= 0
==> default: Loading metadata for box 'debian/bullseye64'
    default: URL: https://vagrantcloud.com/debian/bullseye64
==> default: Adding box 'debian/bullseye64' (v11.20211230.1) for provider: virtualbox
    default: Downloading: https://vagrantcloud.com/debian/boxes/bullseye64/versions/11.20211230.1/providers/virtualbox.box
    default:
==> default: Successfully added box 'debian/bullseye64' (v11.20211230.1) for 'virtualbox'!
==> default: Importing base box 'debian/bullseye64'...
==> default: Matching MAC address for NAT networking...
==> default: Checking if box 'debian/bullseye64' version '11.20211230.1' is up to date...
==> default: Setting the name of the VM: vagrant-debian11-test_default_1641156963418_34483
Vagrant is currently configured to create VirtualBox synced folders with
the `SharedFoldersEnableSymlinksCreate` option enabled. If the Vagrant
guest is not trusted, you may want to disable this option. For more
information on this option, please refer to the VirtualBox manual:

  https://www.virtualbox.org/manual/ch04.html#sharedfolders

This option can be disabled globally with an environment variable:

  VAGRANT_DISABLE_VBOXSYMLINKCREATE=1

or on a per folder basis within the Vagrantfile:

  config.vm.synced_folder '/host/path', '/guest/path', SharedFoldersEnableSymlinksCreate: false
==> default: Clearing any previously set network interfaces...
==> default: Preparing network interfaces based on configuration...
    default: Adapter 1: nat
==> default: Forwarding ports...
    default: 22 (guest) => 2222 (host) (adapter 1)
==> default: Booting VM...
==> default: Waiting for machine to boot. This may take a few minutes...
    default: SSH address: 127.0.0.1:2222
    default: SSH username: vagrant
    default: SSH auth method: private key
    default: Warning: Connection reset. Retrying...
    default:
    default: Vagrant insecure key detected. Vagrant will automatically replace
    default: this with a newly generated keypair for better security.
    default:
    default: Inserting generated public key within guest...
    default: Removing insecure key from the guest if it's present...
    default: Key inserted! Disconnecting and reconnecting using new SSH key...
==> default: Machine booted and ready!
==> default: Checking for guest additions in VM...
    default: The guest additions on this VM do not match the installed version of
    default: VirtualBox! In most cases this is fine, but in rare cases it can
    default: prevent things such as shared folders from working properly. If you see
    default: shared folder errors, please make sure the guest additions within the
    default: virtual machine match the version of VirtualBox you have installed on
    default: your host and reload your VM.
    default:
    default: Guest Additions Version: 6.0.0 r127566
    default: VirtualBox Version: 6.1
==> default: Mounting shared folders...
    default: /vagrant => D:/IPI_DevOps/vagrant-debian11-test

==> default: Machine 'default' has a post `vagrant up` message. This is a message
==> default: from the creator of the Vagrantfile, and not from Vagrant itself:
==> default:
==> default: Vanilla Debian box. See https://app.vagrantup.com/debian for help and bug reports
```

> :warning: **Ajout** : il est de bon ton d'**√©teindre** une VM apr√®s usage, et √©ventuellement (pour cette VM de test) de la supprimer.
> * `vagrant halt` permet d'√©teindre la VM
> * `vagrant destroy` permet de la supprimer d√©finitivement (**√† manier avec pr√©caution** si votre VM contient le fruit de plusieurs heures de travail üòÖ)

## Vagrantfile pour configurer plusieurs VMs

### Obtenir le Vagrantfile et lancer les VMs

Dans votre PowerShell, v√©rifiez l'endroit o√π vous vous trouvez en examinant l'invite de commandes. Elle devrait ressembler √† ceci :

```
PS C:\Users\IPI\Documents\DevOps\TestDebian>
```

√Ä partir de l√†

* **Remonter d'un niveau dans l'arborescence** : `cd ..`
* Cr√©er un nouveau dossier `AnsibleDebian` : `mkdir AnsibleDebian`
* Se placer dans ce dossier :  `cd AnsibleDebian`
* T√©l√©charger un `Vagrantfile` un peu plus complexe, depuis <https://m1cp.bhu.ovh/vagrant-2-vms/Vagrantfile>, en lan√ßant cette commande : `Invoke-WebRequest -Uri "https://m1cp.bhu.ovh/vagrant-2-vms/Vagrantfile" -OutFile ".\Vagrantfile"`
* D√©marrer les VMs : `vagrant up`

La sortie obtenue ressemble a ceci :

```
Bringing machine 'managed-host1' up with 'virtualbox' provider...
Bringing machine 'ansible-host' up with 'virtualbox' provider...
==> managed-host1: Importing base box 'debian/bullseye64'...
==> managed-host1: Matching MAC address for NAT networking...
==> managed-host1: Checking if box 'debian/bullseye64' version '11.20211230.1' is up to date...
==> managed-host1: Setting the name of the VM: vagrant-multi-vms_managed-host1_1641160372389_33571
==> managed-host1: Clearing any previously set network interfaces...
==> managed-host1: Preparing network interfaces based on configuration...
    managed-host1: Adapter 1: nat
    managed-host1: Adapter 2: hostonly
==> managed-host1: Forwarding ports...
    managed-host1: 22 (guest) => 2222 (host) (adapter 1)
==> managed-host1: Running 'pre-boot' VM customizations...
==> managed-host1: Booting VM...
==> managed-host1: Waiting for machine to boot. This may take a few minutes...
    managed-host1: SSH address: 127.0.0.1:2222
    managed-host1: SSH username: vagrant
    managed-host1: SSH auth method: private key
==> managed-host1: Machine booted and ready!
==> managed-host1: Checking for guest additions in VM...
    managed-host1: The guest additions on this VM do not match the installed version of
    managed-host1: VirtualBox! In most cases this is fine, but in rare cases it can
    managed-host1: prevent things such as shared folders from working properly. If you see
    managed-host1: shared folder errors, please make sure the guest additions within the
    managed-host1: virtual machine match the version of VirtualBox you have installed on
    managed-host1: your host and reload your VM.
    managed-host1:
    managed-host1: Guest Additions Version: 6.0.0 r127566
    managed-host1: VirtualBox Version: 6.1
==> managed-host1: Setting hostname...
==> managed-host1: Configuring and enabling network interfaces...
==> ansible-host: Importing base box 'debian/bullseye64'...
==> ansible-host: Matching MAC address for NAT networking...
==> ansible-host: Checking if box 'debian/bullseye64' version '11.20211230.1' is up to date...
==> ansible-host: Setting the name of the VM: vagrant-multi-vms_ansible-host_1641160427644_1154
==> ansible-host: Fixed port collision for 22 => 2222. Now on port 2200.
==> ansible-host: Clearing any previously set network interfaces...
==> ansible-host: Preparing network interfaces based on configuration...
    ansible-host: Adapter 1: nat
    ansible-host: Adapter 2: hostonly
==> ansible-host: Forwarding ports...
    ansible-host: 22 (guest) => 2200 (host) (adapter 1)
==> ansible-host: Running 'pre-boot' VM customizations...
==> ansible-host: Booting VM...
==> ansible-host: Waiting for machine to boot. This may take a few minutes...
    ansible-host: SSH address: 127.0.0.1:2200
    ansible-host: SSH username: vagrant
    ansible-host: SSH auth method: private key
==> ansible-host: Machine booted and ready!
==> ansible-host: Checking for guest additions in VM...
    ansible-host: The guest additions on this VM do not match the installed version of
    ansible-host: VirtualBox! In most cases this is fine, but in rare cases it can
    ansible-host: prevent things such as shared folders from working properly. If you see
    ansible-host: shared folder errors, please make sure the guest additions within the
    ansible-host: virtual machine match the version of VirtualBox you have installed on
    ansible-host: your host and reload your VM.
    ansible-host:
    ansible-host: Guest Additions Version: 6.0.0 r127566
    ansible-host: VirtualBox Version: 6.1
==> ansible-host: Setting hostname...
==> ansible-host: Configuring and enabling network interfaces...

==> managed-host1: Machine 'managed-host1' has a post `vagrant up` message. This is a message
==> managed-host1: from the creator of the Vagrantfile, and not from Vagrant itself:
==> managed-host1:
==> managed-host1: Vanilla Debian box. See https://app.vagrantup.com/debian for help and bug reports

==> ansible-host: Machine 'ansible-host' has a post `vagrant up` message. This is a message
==> ansible-host: from the creator of the Vagrantfile, and not from Vagrant itself:
==> ansible-host:
==> ansible-host: Vanilla Debian box. See https://app.vagrantup.com/debian for help and bug reports
```

Les VMs √©tant d√©marr√©es, on va encore devoir faire un peu de configuration, avant de se pencher sur Ansible proprement dit !

### Premi√®re connexion aux VMs

Pour tester la connexion vers chaque VM via SSH, on va √† nouveau utiliser `vagrant ssh`.

Comme on dispose maintenant de deux VMs, il va cette fois falloir sp√©cifier sur quelle machine on souhaite se connecter.

Commen√ßons par nous connecter sur la VM faisant office de contr√¥leur Ansible : 

    vagrant ssh ansible-host

On doit voir appara√Ætre un prompt (invite de commandes) ressemblant √† ceci :

    vagrant@ansible-host: $

Enfin, testons l'acc√®s √† Internet :

    ping google.fr

On doit voir s'afficher des s√©quences d'√©change indiquant le temps mis pour la requ√™te √† faire l'aller retour :

    vagrant@ansible-host:~$ ping google.fr
    PING google.fr (142.251.37.163) 56(84) bytes of data.
    64 bytes from mrs09s14-in-f3.1e100.net (142.251.37.163): icmp_seq=1 ttl=116 time=9.00 ms
    64 bytes from mrs09s14-in-f3.1e100.net (142.251.37.163): icmp_seq=2 ttl=116 time=7.94 ms
    64 bytes from mrs09s14-in-f3.1e100.net (142.251.37.163): icmp_seq=3 ttl=116 time=8.95 ms

Dans le cas contraire, rien ne s'affiche sous la ligne `PING`.

On peut se d√©connecter (`logout`), puis effectuer la m√™me op√©ration pour la VM faisant office de serveur contr√¥l√© par Ansible : `vagrant ssh managed-host1`. De m√™me, testons l'acc√®s √† Internet : `ping google.fr`. Puis `logout` une fois qu'on a v√©rifi√© que cela fonctionnait.

## Configuration des VMs

`vagrant ssh` permet de se connecter de notre syst√®me h√¥te (la machine Windows) vers les syst√®mes "invit√©s" (les VMs).

**Note** : Si on n'utilisait pas Vagrant, on utiliserait simplement la commande `ssh` pour se connecter aux VMs. Ce serait le cas si on avait utilis√© VirtualBox directement. Le revers de la m√©daille est qu'on aurait eu un peu plus de configuration √† effectuer.

Gardez juste en t√™te que `vagrant ssh` est sp√©cifique √† ce "setup" bas√© sur Vagrant. Ceci dit, nous allons quand m√™me utiliser `ssh` pour permettre au _control node_ Ansible de se connecter au(x) _managed node(s)_ (ici un seul).

### Tentative de connexion du _control node_ au _managed node_

Dans le `Vagrantfile` qui a servi √† initialiser les 2 VMs, on a attribu√© une adresse IP statique √† chacune des VMs, qui sont sur le m√™me r√©seau LAN "interne" :

* `192.168.56.1` pour `ansible-host`
* `192.168.56.10` pour `managed-host1`

Essayons de nous connecter du 1er au 2nd :

* Se connecter √† `ansible-host` depuis le syst√®me Windows : `vagrant ssh ansible-host`
* Une fois qu'on est connect√© : `ssh 192.168.56.10`
* On obtient un message d'erreur : `vagrant@192.168.56.1: Permission denied (publickey).`

√Ä ce stade, il peut √™tre int√©ressant de rappeler quelques bases sur SSH !

**S**ecure **SH**ell permet de cr√©er un tunnel s√©curis√© entre deux machines : s√©curis√©, car les informations qui transitent sont chiffr√©es.

SSH repose sur le chiffrement asym√©trique. C'est un sujet assez complexe et qui d√©passe le cadre de ce cours, mais en tr√®s bref, on a besoin de g√©n√©r√© une paire de cl√©s (_keypair_, parfois d√©nomm√©e bicl√© en fran√ßais) :

* Une cl√© priv√©e qui doit rester sur le serveur **depuis lequel on se connecte**
* Une cl√© publique qu'on va placer sur le serveur **auquel on souhaite se connecter**

N'ayant pas pour l'instant de paire de cl√©s, on ne peut pour l'instant pas se connecter du _control node_ au _managed node_.

### G√©n√©ration d'une paire de cl√©s SSH

> :warning: Section qui sera revue suite aux probl√®mes rencontr√©.e.s par certain.e.s ave Vagrant : en effet, une partie est commune √† Vagrant et Virtualbox, une partie est sp√©cifique √† Vagrant.

On va g√©n√©rer une paire de cl√©s SSH, depuis le _control node_, via la commande `ssh-keygen`.

L'un de ses nombreux arguments accept√©s par cette commande est le type de cl√© (algorithme utilis√©), via `-t` suivi d'un type. Entre autres types possibles : `dsa`, `rsa` (plut√¥t obsol√®tes d√©sormais), `ecdsa`, etc.

On va cr√©er une paire de cl√©s de type ECDSA :

    ssh-keygen -t ecdsa

On nous demande alors l'emplacement o√π sauvegarder la cl√© :

    Generating public/private ecdsa key pair.
    Enter file in which to save the key (/home/vagrant/.ssh/id_ecdsa):

Il suffit de valider avec entr√©e, pour garder le choix par d√©faut `/home/vagrant/.ssh/id_ecdsa`.

On nous demande ensuite une "passphrase" :

    Enter passphrase (empty for no passphrase):

Par souci de simplicit√©, on va valider avec entr√©e **deux fois** pour g√©n√©rer la paire de cl√©s sans passphrase. Ce n'est pas s√©curis√©, mais cela simplifiera l'exercice.

> Dans un environnement professionnel, on cherchera √† augmenter le niveau de s√©curit√© en sp√©cifiant une passphrase : 15 caract√®res minimum, 20 de pr√©f√©rence, √† stocker dans un gestionnaire de mots de passe. Des outils (`ssh-agent` et `ssh-add`) permettront d'√©viter d'avoir √† la saisir trop souvent.

Apr√®s la validation de la passphrase vide, on obtient des informations sur l'emplacement des cl√©s priv√©e (`id_ecdsa`) et publique (`id_ecdsa.pub`), l'empreinte de la cl√©, et un "randomart" qui peut servir √† valider la cl√© de fa√ßon visuelle (ce qu'on ne fera pas ici) :

```
Your identification has been saved in /home/vagrant/.ssh/id_ecdsa
Your public key has been saved in /home/vagrant/.ssh/id_ecdsa.pub
The key fingerprint is:
SHA256:xQbzm8dGcJPISgLAsI80CkkHlWAJzKfTEp+xFdAQv2A vagrant@ansible-host
The key's randomart image is:
+---[ECDSA 256]---+
|*B*BBo. o...o.   |
|oBo+.o. .=oo..   |
|+o*E=. o .= .    |
|+*o=. . .o =     |
|o +  .  S o +    |
|           o     |
|                 |
|                 |
|                 |
+----[SHA256]-----+
```

On peut v√©rifier la pr√©sence des cl√©s dans le dossier `.ssh` :

    ls -al .ssh

Affichage produit :

    total 24
    drwx------ 2 vagrant vagrant 4096 Jan  2 23:50 .
    drwxr-xr-x 3 vagrant vagrant 4096 Jan  2 23:45 ..
    -rw------- 1 vagrant vagrant  409 Dec 30 17:14 authorized_keys
    -rw------- 1 vagrant vagrant  513 Jan  2 23:50 id_ecdsa
    -rw-r--r-- 1 vagrant vagrant  182 Jan  2 23:50 id_ecdsa.pub
    -rw-r--r-- 1 vagrant vagrant  222 Jan  2 21:56 known_hosts

Profitons-en pour expliquer le r√¥le des deux autres fichiers :

* `known_hosts` permet de stocker les "empreintes" des serveurs auxquels on se connecte, et de v√©rifier qu'elles n'ont pas chang√© lors de connexions ult√©rieures (ce qui indiquerait vraisemblablement une attaque).
* `authorized_keys` est l'endroit o√π on va stocker les cl√©s publiques qu'on veut autoriser √† se connecter sous ce compte utilisateur.

**La prochaine √©tape** va √™tre de copier la cl√© publique (`id_ecdsa.pub`) vers le fichier `authorized_keys` de la machine sur laquelle on veut se connecter&hellip; ce qu'on ferait normalement via la commande `ssh-copy-id`, de cette fa√ßon (on indique en dernier l'IP ou le nom d'h√¥te de la machine cible, √©ventuellement pr√©c√©d√© d'un nom d'utilisateur s√©par√© de l'IP par un `@`). Cette commande est un **exemple**, ne la lancez pas !

```
ssh-copy-id -i ~/.ssh/id_ecdsa.pub someuser@192.168.56.10
```

Probl√®me : en l'√©tat actuel, on ne peut pas se connecter en SSH, ainsi qu'on l'a vu pr√©c√©demment ! Il y a heureusement plusieurs parades.

Quittez la VM en saisissant `logout`.

### Transferer la cl√© publique

√Ä nouveau, cette √©tape est un peu sp√©cifique au setup bas√© sur Vagrant.

Installez le plugin `vagrant-scp`, qui va permettre de faire des copies entre les machines virtuelles et le syst√®me h√¥te Windows.
    
```
vagrant plugin install vagrant-scp
```

Ensuite, on va pouvoir r√©cup√©rer la cl√© publique depuis `ansible-host` :

```
vagrant scp ansible-host:.ssh/id_ecdsa.pub .
```

Note : `vagrant scp` utilise la m√™me syntaxe que `scp` (secure copy). Il y a ici deux arguments :

* `ansible-host:.ssh/id_ecdsa.pub` est la source. Avant le `:`, on trouve la machine depuis laquelle on veut r√©cup√©rer un fichier. Apr√®s le `:`, on trouve le chemin relatif au compte utilisateur (`/home/vagrant`) propri√©taire du fichier : `.ssh/id_ecdsa.pub`.
* `.` d√©signe le r√©pertoire courant sur la machine cible

Puis on va copier la cl√© vers `managed-host1` :

```
vagrant scp id_ecdsa.pub managed-host1:
```

Ici, `id_ecdsa.pub` est la source (situ√©e dans le r√©pertoire courant du syst√®me h√¥te), et `managed-host1:` est la destination (implicitement, le r√©pertoire `/home/vagrant` sur `managed-host1`).

On va maintenant se connecter au `managed-host1` :

    vagrant ssh managed-host1

Puis on peut constater que la cl√© publique s'y trouve bien en lan√ßant `ls`. Ensuite, il va falloir ajouter le contenu de ce fichier au fichier `.ssh/authorized_keys`. On va d√©tailler un peu l'op√©ration.

D'abord, visualisez le contenu actuel du fichier `.ssh/authorized_keys` :

```
vagrant@managed-host1:~$ cat .ssh/authorized_keys
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ== vagrant insecure public key
```

Visualisez maintenant le contenu de `id_ecdsa.pub` :

```
vagrant@managed-host1:~$ cat id_ecdsa.pub
ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBBSkxnUn57qBx+qMTLuxPWoV41hrXOVKAt4lYeIb/jOYjuIWprwFZRxBBlXf+VnfbJbEWnSQIEqmp9Bii2Sayfs= vagrant@ansible-host
```

Cette commande d√©riv√©e de la pr√©c√©dente permet de **rediriger** son affichage, en l'ajoutant (via `>>`) au contenu de `authorized_keys`.

    cat id_ecdsa.pub >> .ssh/authorized_keys

Visualisez √† nouveau `authorized_keys` :

```
vagrant@managed-host1:~$ cat .ssh/authorized_keys
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ== vagrant insecure public key
ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBBSkxnUn57qBx+qMTLuxPWoV41hrXOVKAt4lYeIb/jOYjuIWprwFZRxBBlXf+VnfbJbEWnSQIEqmp9Bii2Sayfs= vagrant@ansible-host
```

La cl√© a bien √©t√© ajout√©e ! Quittez la session SSH via `logout`.

### Retour au _control node_

Connexion au control node :

    vagrant ssh ansible-host

√Ä nouveau, tenative de connexion via `ssh` :

    ssh 192.168.56.10

Cette fois-ci, cela fonctionne !

```
vagrant@ansible-host:~$ ssh 192.168.56.10
Linux managed-host1 5.10.0-10-amd64 #1 SMP Debian 5.10.84-1 (2021-12-08) x86_64

The programs included with the Debian GNU/Linux system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
Last login: Mon Jan  3 00:20:27 2022 from 10.0.2.2
```

Quittez avec `logout` (raccourci : `Ctrl-D`) pour revenir au control node.

## Ansible

**Important** : Ansible ne doit √™tre install√© _que_ sur le control node. Sur les h√¥tes contr√¥l√©s par Ansible, il n'y a rien √† installer !

C'est un des points forts d'Ansible, compar√© √† d'autres outils qui n√©cessitent l'installation d'un "agent" sur les machines contr√¥l√©es.

Ansible est "agentless" : il a juste besoin de pouvoir acc√©der aux noeuds contr√¥l√©s via SSH. 

### Installation d'Ansible sur le control node

On arrive enfin au vif du sujet : l'installation d'Ansible !

**V√©rifiez que vous √™tes bien sur le control node**, en inspectant l'invite de commandes :

```
vagrant@ansible-host:~$
```

Il existe plusieurs fa√ßons d'installer Ansible, ainsi que l'indique la section [Installing Ansible](https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html) de la documentation officielle.

Nous allons suivre les instructions de la sous-section [Installing Ansible on Debian](https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html#installing-ansible-on-debian).

Elle repose sur l'utilisation de l'outil natif de gestion de paquets logiciels commun √† Debian et Ubuntu : `apt`. Cette commande permet notamment d'installer des logiciels depuis des "dep√¥ts" publics.

La premi√®re chose √† faire est de passer sous le compte `root` :

    sudo su -

Ensuite, on doit mettre a jour la liste des paquets logiciels disponibles :

    apt-get update
    
Puis installer le paquet `gnupg` (outil de chiffrement requis par l'une des commandes suivantes, `apt-key`) :

    apt install -y gnupg

Ensuite, il faut ajouter l'adresse du d√©p√¥t Ansible pour Ubuntu 20 `focal`, qui marche aussi pour Debian 11 `bullseye`, au fichier `/etc/apt/sources.list.d/ansible.list` :

    echo "deb http://ppa.launchpad.net/ansible/ansible/ubuntu focal main" >> /etc/apt/sources.list.d/ansible.list

Avec cette commande, on affiche la ligne de d√©finition du d√©p√¥t avec `echo`, et on redirige cet affichage vers le fichier `/etc/apt/sources.list.d/ansible.list`, qui est cr√©√© s'il n'existait pas.

Ensuite, on doit ajouter une cl√© permettant d'authentifier les paquets :

    apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 93C4A3FD7BB9C367

Ensuite, on lance √† nouveau `apt-get update`, qui permet d'aller chercher la liste des paquets disponibles dans le d√©p√¥t ajout√© pr√©c√©demment :

    apt-get update

Enfin, on installe Ansible (`-y` permet de passer l'√©tape de confirmation) :

    apt install -y ansible

Cette √©tape va prendre un peu de temps.

**Restez en `root` pour l'√©tape suivante** (il ne faudra pas oublier d'en ressortir quand on aura termin√© toute la configuration).

### Configuration des h√¥tes

On doit maintenant indiquer √† Ansible la liste des h√¥tes qu'il contr√¥le. Par d√©faut, c'est dans le fichier `/etc/ansible/hosts` qu'on les r√©f√©rence.

> :warning: **Ajout** : il est plut√¥t recommand√©, par certains, de cr√©er des fichiers d'inventaire (_inventory_) par projet, afin d'y r√©f√©rencer les h√¥tes concern√©s par ce projet. L'approche que nous adoptons ici nous √©vitera d'avoir √† sp√©cifier un fichier d'inventaire √† chaque lancement d'`ansible`.

Les h√¥tes peuvent √™tre rassembl√©s dans des groupes. Ici, on aura juste un groupe (`webservers`) qui contiendra la machine √† contr√¥ler, qu'on indiquera via son adresse IP.

Lancez l'√©diteur `nano` pour √©diter le fichier d'h√¥tes :

    nano /etc/ansible/hosts

Son contenu par d√©faut est celui indiqu√© ci-dessous. Toutes les lignes sont pr√©c√©d√©es du `#` (commentaires).

D√©commentez la ligne `## [webservers]`, en enlevant les deux `#` **et l'espace qui les suit**.

Sous cette ligne, ins√©rez l'adresse IP de l'h√¥te √† contr√¥ler :

```
192.168.56.10
```

Vous devez donc avoir ces deux lignes cons√©cutives :

```
[webservers]
192.168.56.10
```

Sauvegardez le fichier avec le raccourci Ctrl-O. **Observez bien le bas de l'√©cran**, o√π on vous propose d'indiquer le nom du fichier √† √©crire :

    File Name to Write: /etc/ansible/hosts 

Vous n'avez ici **qu'√† valider le choix propos√© avec entr√©e**.

Puis utilisez le raccourci Ctrl-X pour quitter `nano`.

**Enfin**, quittez le mode `root` via Ctrl-D ou la commande `logout`.

### Tester le bon fonctionnement d'Ansible

On va enfin pouvoir ex√©cuter nos premi√®res commandes Ansible. Commencez par celle-ci :

    ansible all -m ping

Elle devrait, si tout va bien, se solder par l'affichage suivant :

```
192.168.56.10 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "changed": false,
    "ping": "pong"
}
```

Quelques explictions s'imposent ! D'abord, l'anatomie de la commande `ansible all -m ping` :

`all` permet de lancer une commande sur _tous_ les h√¥tes r√©f√©renc√©s dans le fichier `/etc/ansible/hosts`. On aurait pu sp√©cifier `webservers` au lieu de `all`. Essayez !

Vous constaterez que cela ne change rien, et c'est normal, car on n'a qu'un seul h√¥te contr√¥l√© (choix assez prudent de ma part, je crains les limites en termes de RAM des ordinateurs de certain.e.s d'entre vous !).

`-m` permet de sp√©cifier un "module". Ici `ping`. Un module est un genre de "plugin" qui contient des fonctionnalit√©s. C'est une sorte de script qui va √™tre ex√©cut√© sur les machines contr√¥l√©es, et va renvoyer des informations sous la forme d'une cha√Æne JSON.

Le module `ping` ne doit pas √™tre confondu avec la commande `ping` du m√™me nom (laquelle permet de v√©rifier qu'on peut joindre un certain h√¥te sur le r√©seau). Elle en est cependant l'√©quivalent dans Ansible : elle essaie de se connecter √† l'h√¥te, v√©rifie que Python est install√© et utilisable, et retourne `pong` si tout s'est bien pass√©.

### Commandes ad hoc

Ce qu'on vient de voir est une _ad hoc command_ ou commande ad hoc : cela permet d'ex√©cuter une t√¢che sp√©cifique sur tous les h√¥tes cibl√©s.

Les commandes ad hoc sont simples et rapides √† utiliser, mais ne sont pas r√©utilisables. On verra plus loin le concept de "playbooks", permettant de cr√©er des ensembles de t√¢ches r√©utilisables.

En attendant, les commandes ad hoc ont leur utilit√©. Des exemples sont donn√©s dans la section [Introduction to ad hoc commands](https://docs.ansible.com/ansible/latest/user_guide/intro_adhoc.html) de la doc Ansible.

On y pr√©cise l'anatomie d'une commande ad hoc :

    ansible [pattern] -m [module] -a "[module options]"

#### Param√®tres de modules

`-a` permet de passer des options sp√©cifiques √† un certain module.

Si on se rend sur la documentation du [module ping](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/ping_module.html), on voit, sous la section "Parameters", qu'il accepte le param√®tre `data`, qui d√©finit la donn√©e √† renvoyer en cas de succ√®s, et dont la valeur par d√©faut est `pong`.

Essayez ceci, pour changer la valeur de retour :

    ansible all -m ping -a data=hello

On constate que cela a eu l'effet escompt√© :

    192.168.56.10 | SUCCESS => {
        "ansible_facts": {
            "discovered_interpreter_python": "/usr/bin/python3"
        },
        "changed": false,
        "ping": "hello"
    }

Essayons une autre commande ad hoc. On va utiliser le module `apt` d'Ansible, qui permet de g√©rer les packages logiciels sur les h√¥tes contr√¥l√©s, via la commande `apt` que nous avions utilis√©e, manuellement, pour installer Ansible.

    ansible all -m ansible.builtin.apt -a "name=curl state=present"

Ceci permet d'installer le module `curl` s'il n'est pas pr√©sent.

On obtient le message suivant :

```
192.168.56.10 | FAILED! => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "changed": false,
    "msg": "No package matching 'curl' is available"
}
```

C'est √©tonnant, car le module `curl` est disponibles dans toutes les distributions Linux, et est m√™me, le plus souvent, install√© par d√©faut !

Ici, il nous faut ajouter un param√®tre permettant d'ex√©cuter `apt update` que nous avions √©galement utilis√©e pr√©c√©demment. Ce param√®tre est `update_cache` et il faut le positionner √† `yes` (voir la doc du module [ansible.builtin.apt](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/apt_module.html)).


    ansible all -m ansible.builtin.apt -a "name=curl state=present update_cache=yes"

Ceci va prendre un peu de temps ! On √©cope √† nouveau d'un message d'erreur, quelque peu diff√©rent :

```
192.168.56.10 | FAILED! => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "changed": false,
    "msg": "Failed to lock apt for exclusive operation: Failed to lock directory /var/lib/apt/lists/: E:Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)"
}
```

Ce message d'erreur est quelque peu cryptique, mais est facilement explicable : la gestion des paquets logiciels est du ressort de l'administrateur du syst√®me, l'utilisateur `root`.

#### Obtention des privil√®ges root

Le probl√®me est qu'ici, la commande `apt-get` a √©t√© invoqu√©e sur l'h√¥te cible avec les droits de l'utilisateur `vagrant`.

On va relancer la commande en ajoutant, juste derri√®re `ansible`, le param√®tre `--become` qui va permettre de devenir `root` pour ex√©cuter les commandes sur le syst√®me cible.

    ansible --become all -m ansible.builtin.apt -a "name=curl state=present update_cache=yes"

√Ä nouveau, cela prend un peu de temps. Normalement, le r√©sultat devrait √™tre semblable √† ceci :

```
192.168.56.10 | CHANGED => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "cache_update_time": 1641178826,
    "cache_updated": true,
    "changed": true,
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Reading package lists...\nBuilding dependency tree...\nReading state information...\nThe following additional packages will be installed:\n  libcurl4\nThe following NEW packages will be installed:\n  curl libcurl4\n0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 608 kB of archives.\nAfter this operation, 1186 kB of additional disk space will be used.\nGet:1 http://deb.debian.org/debian bullseye/main amd64 libcurl4 amd64 7.74.0-1.3+deb11u1 [341 kB]\nGet:2 http://deb.debian.org/debian bullseye/main amd64 curl amd64 7.74.0-1.3+deb11u1 [267 kB]\nFetched 608 kB in 0s (6271 kB/s)\nSelecting previously unselected package libcurl4:amd64.\r\n(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 25131 files and directories currently installed.)\r\nPreparing to unpack .../libcurl4_7.74.0-1.3+deb11u1_amd64.deb ...\r\nUnpacking libcurl4:amd64 (7.74.0-1.3+deb11u1) ...\r\nSelecting previously unselected package curl.\r\nPreparing to unpack .../curl_7.74.0-1.3+deb11u1_amd64.deb ...\r\nUnpacking curl (7.74.0-1.3+deb11u1) ...\r\nSetting up libcurl4:amd64 (7.74.0-1.3+deb11u1) ...\r\nSetting up curl (7.74.0-1.3+deb11u1) ...\r\nProcessing triggers for man-db (2.9.4-2) ...\r\nProcessing triggers for libc-bin (2.31-13+deb11u2) ...\r\n",
    "stdout_lines": [
        "Reading package lists...",
        "Building dependency tree...",
        "Reading state information...",
        "The following additional packages will be installed:",
        "  libcurl4",
        "The following NEW packages will be installed:",
        "  curl libcurl4",
        "0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.",
        "Need to get 608 kB of archives.",
        "After this operation, 1186 kB of additional disk space will be used.",
        "Get:1 http://deb.debian.org/debian bullseye/main amd64 libcurl4 amd64 7.74.0-1.3+deb11u1 [341 kB]",
        "Get:2 http://deb.debian.org/debian bullseye/main amd64 curl amd64 7.74.0-1.3+deb11u1 [267 kB]",
        "Fetched 608 kB in 0s (6271 kB/s)",
        "Selecting previously unselected package libcurl4:amd64.",
        "(Reading database ... ",
        "(Reading database ... 5%",
        "(Reading database ... 10%",
        "(Reading database ... 15%",
        "(Reading database ... 20%",
        "(Reading database ... 25%",
        "(Reading database ... 30%",
        "(Reading database ... 35%",
        "(Reading database ... 40%",
        "(Reading database ... 45%",
        "(Reading database ... 50%",
        "(Reading database ... 55%",
        "(Reading database ... 60%",
        "(Reading database ... 65%",
        "(Reading database ... 70%",
        "(Reading database ... 75%",
        "(Reading database ... 80%",
        "(Reading database ... 85%",
        "(Reading database ... 90%",
        "(Reading database ... 95%",
        "(Reading database ... 100%",
        "(Reading database ... 25131 files and directories currently installed.)",
        "Preparing to unpack .../libcurl4_7.74.0-1.3+deb11u1_amd64.deb ...",
        "Unpacking libcurl4:amd64 (7.74.0-1.3+deb11u1) ...",
        "Selecting previously unselected package curl.",
        "Preparing to unpack .../curl_7.74.0-1.3+deb11u1_amd64.deb ...",
        "Unpacking curl (7.74.0-1.3+deb11u1) ...",
        "Setting up libcurl4:amd64 (7.74.0-1.3+deb11u1) ...",
        "Setting up curl (7.74.0-1.3+deb11u1) ...",
        "Processing triggers for man-db (2.9.4-2) ...",
        "Processing triggers for libc-bin (2.31-13+deb11u2) ..."
    ]
}
```

Notez le d√©but de cette sortie : `192.168.56.10 | CHANGED`.

Cela signifie que la commande a bien effectu√© des changements sur le syst√®me cible. Relancez-la (fl√®che du haut puis entr√©e).

Cette fois, le r√©sultat est diff√©rent :

```
192.168.56.10 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "cache_update_time": 1641178826,
    "cache_updated": false,
    "changed": false
}
```

La commande a r√©ussi, mais n'a appliqu√© aucun changement sur le syst√®me cible, `curl` ayant d√©j√† install√© par l'invocation pr√©c√©dente.

### Playbooks

Voir la section [Intro to playbooks](https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html) de la documentation officielle pour r√©f√©rence.

Les playbooks Ansible permettent de sp√©cifier des t√¢ches √† ex√©cuter sur diff√©rentes machines. D√®s lors qu'on souhaite ex√©cuter une certaine t√¢che plus d'une fois, il est pr√©f√©rable de recourir aux playbooks.

Un playbook est un fichier au format YAML, qui peut (et doit) √™tre g√©r√© via un outil de gestion de versions tel que Git.

Ainsi, une fois √©crit, le playbook pourra √™tre r√©utilis√©.

#### Un exemple simple

Voici un playbook tr√®s simple, qui va effectuer la m√™me chose que ce qu'on avait fait pr√©c√©demment avec une commande ad hoc, pour installer `curl`.

```yaml
---
- name: Install curl
  hosts: webservers

  tasks:
  - name: Ensure curl is at the latest version
    ansible.builtin.apt:
      name: curl
      state: latest
    become: yes
```

Ce playbook d√©finit une seule t√¢che, qui comporte :

* un nom (`name`)
* un module (`ansible.builtin.apt`) et des param√®tres associ√©s
* Le param√®tre `become` positionn√© sur `yes`, indiquant qu'il faut obtenir les privil√®ges `root` afin d'ex√©cuter la commande

Copiez le bloc de configuration ci-dessus. Dans la fen√™tre de PowerShell, toujours connect√©e sur `ansible-host`, lancez :

    nano playbook-curl.yaml

Puis collez le contenu copi√©, sauvegardez (Ctrl-O puis entr√©e), et quittez (Ctrl-X).

Enfin, ex√©cutez le playbook en utilisant la commande `ansible-playbook`, suivi du nom du playbook :

    ansible-playbook playbook-curl.yaml

Celle-ci produit l'affichage suivant :

```

PLAY [Install curl] ***********************************************************************************************

TASK [Gathering Facts] ********************************************************************************************
ok: [192.168.56.10]

TASK [Ensure curl is at the latest version] ***********************************************************************
ok: [192.168.56.10]

PLAY RECAP ********************************************************************************************************
192.168.56.10              : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

```

Entre autres choses, on peut noter, √† la fin, `changed=0`, ce qui signifie que le playbook n'a effectu√© aucun changement (`curl` √©tant d√©j√† install√© sur l'h√¥te cible).

#### La syntaxe YAML

Avant d'aller plus loin, il peut √™tre int√©ressant de se familiariser avec la syntaxe YAML. D'autant plus qu'elle n'est pas sp√©cifique √† Ansible, loin de l√† !

On l'utilise √©galement :

* Dans le monde du DevOps, pour configurer des outils tels que Docker Compose ou Kubernetes
* Pour d'autres outils, tels que Jekyll (g√©n√©rateur de site statique √† partir de fichiers Markdown, dont l'en-t√™te est au format YAML)

Quelques ressources (choisissez le format qui vous convient le mieux) :

* La section [YAML Syntax](https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html#yaml-syntax) de la doc Ansible
* [Introduction √† YAML](https://sweetohm.net/article/introduction-yaml.html) en fran√ßais, mais avec des exemples de manipulation du format YAML en Python, pour les t√©m√©raires !
* [YAML Tutorial | Learn YAML in 18 mins](https://www.youtube.com/watch?v=1uFVr15xDGg) vid√©o en anglais (d'une autrice qui propose √©norm√©ment de contenus tr√®s qualitatifs sur le DevOps)

#### Installer un serveur web

Source dont on s'inspire largement : <https://iac.goffinet.org/ansible-linux/un-premier-playbook/>

Aller dans la section "4. un premier livre de jeu". Un exemple de config YAML est donn√©.

On ne va prendre (copier dans le presse-papier) que les lignes jusqu'√† la premi√®re t√¢che :

```yaml
---
- name: Configure webserver with nginx
  hosts: webservers
  become: True
  become_method: sudo
  tasks:
    - name: install nginx
      apt:
        name: nginx
        update_cache: yes
```

**Sur le `ansible-host`** (sans √™tre `root`) :

* Editer un nouveau fichier : `nano debian-nginx.yaml`
* Y coller le bloc ci-dessus

Puis ex√©cuter le playbook : `ansible-playbook debian-nginx.yaml`

Il est _possible_ de rencontrer une erreur √† ce stade, ce qui a √©t√© mon cas !

```
vagrant@ansible-host:~/nginx$ ansible-playbook debian-nginx.yaml 

PLAY [Configure webserver with nginx] ****************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [192.168.56.2]

TASK [install nginx] *********************************************************************************
fatal: [192.168.56.2]: FAILED! => {"changed": false, "msg": "Failed to update apt cache: E:Release file for http://deb.debian.org/debian/dists/bullseye-updates/InRelease is not valid yet (invalid for another 2h 46min 20s). Updates for this repository will not be applied., E:Release file for http://deb.debian.org/debian/dists/bullseye-backports/InRelease is not valid yet (invalid for another 2h 46min 20s). Updates for this repository will not be applied."}

PLAY RECAP *******************************************************************************************
192.168.56.2               : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

```

L'erreur provient de probl√®mes sur les d√©p√¥ts `bullseye-updates` et `bullseye-backports` r√©f√©renc√©s dans `/etc/apt/sources.list`.

Dans ce cas et **dans ce cas seulement**, ajouter cette t√¢che au-dessus de la t√¢che "install nginx" de `debian-nginx.yaml` :

```
    - name: disable bullseye-updates and bullseye-backports
      replace:
        path: /etc/apt/sources.list
        regexp: '^deb(-src)? (.*) bullseye-(updates|backports) main'
        replace: '#deb\1 \2 bullseye-\3 main'
```

Cela permet d'ajouter un `#` dans les lignes incrimin√©es de `/etc/apt/sources.list`, afin de d√©sactiver ces d√©p√¥ts (ce qui n'aura normalement pas d'incidence pour la suite).

**Si tout se passe bien**, on va passer √† la suite. Toujours dans le m√™me dossier, lancez cette commande :

    wget https://github.com/bhubr/ipi-devops/raw/master/sample-playbooks/nginx/nginx.tar

Cela vous permet de r√©cup√©rer une archive "tar" (le format d'archive natif d'Unix) contenant des fichiers suppl√©mentaires pour nginx :

* Un fichier de configuration,
* Un fichier `index.html`,

Qui vont remplacer ceux fournis par d√©faut avec nginx.

D√©compressez cette archive :

    tar xvf nginx.tar

Cela devrait afficher la liste des fichiers :

```
files/._nginx.conf
files/nginx.conf
templates/index.html
```

(le fichier `files/._nginx.conf` ne sert √† rien et a √©t√© ajout√© automatiquement par mon Mac !)

Ensuite, √©ditez √† nouveau le fichier du playbook nginx : `nano debian-nginx.yaml`.

Ajoutez, sous la t√¢che "install nginx", les deux t√¢ches suivantes :

```
    - name: copy nginx config file
      copy:
        src: files/nginx.conf
        dest: /etc/nginx/sites-available/default
    - name: enable configuration
      file:
        dest: /etc/nginx/sites-enabled/default
        src: /etc/nginx/sites-available/default
        state: link
```

Puis rejouez le playbook : `ansible-playbook debian-nginx.yaml`

Sortie attendue (√† ceci pr√®s que vous n'aurez pas la t√¢che "[disable bullseye-updates and bullseye-backports") :

```
vagrant@ansible-host:~$ ansible-playbook debian-nginx.yaml 

PLAY [Configure webserver with nginx] ***************************************************************************************

TASK [Gathering Facts] ******************************************************************************************************
ok: [192.168.56.2]

TASK [disable bullseye-updates and bullseye-backports] **********************************************************************
ok: [192.168.56.2]

TASK [install nginx] ********************************************************************************************************
ok: [192.168.56.2]

TASK [copy nginx config file] ***********************************************************************************************
changed: [192.168.56.2]

TASK [enable configuration] *************************************************************************************************
ok: [192.168.56.2]

PLAY RECAP ******************************************************************************************************************
192.168.56.2               : ok=5    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

```

√âditez encore (une derni√®re fois) `debian-nginx.yaml` et ajoutez ces deux t√¢ches √† la fin (attention, ici on a fait une petite modif par rapport √† l'original du tutoriel) :

```
    - name: copy index.html
      template:
        src: templates/index.html
        dest: /usr/share/nginx/html/index.html
        mode: 0644
    - name: restart nginx
      service:
        name: nginx
        state: restarted
```

Rejouez le playbook :

```
vagrant@ansible-host:~$ ansible-playbook debian-nginx.yaml 

PLAY [Configure webserver with nginx] ***************************************************************************************

TASK [Gathering Facts] ******************************************************************************************************
ok: [192.168.56.2]

TASK [disable bullseye-updates and bullseye-backports] **********************************************************************
ok: [192.168.56.2]

TASK [install nginx] ********************************************************************************************************
ok: [192.168.56.2]

TASK [copy nginx config file] ***********************************************************************************************
ok: [192.168.56.2]

TASK [enable configuration] *************************************************************************************************
ok: [192.168.56.2]

TASK [copy index.html] ******************************************************************************************************
changed: [192.168.56.2]

TASK [restart nginx] ********************************************************************************************************
changed: [192.168.56.2]

PLAY RECAP ******************************************************************************************************************
192.168.56.2               : ok=7    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

```

On peut noter que les t√¢ches d√©j√† ex√©cut√©es lors de l'ex√©cution pr√©c√©dente ne provoquent cette fois pas de changement.

#### Requ√™ter notre serveur web

Il va vous falloir installer `curl` sur l'`ansible-host` :

    sudo su -
    apt install -y curl
    logout

Puis vous pouvez interroger le serveur via son IP :

    curl http://192.168.56.10

Vous devriez voir s'afficher :

```
vagrant@ansible-host:~$ curl http://192.168.56.10
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Nginx on Debian</title>
</head>
<body>
  <h1>It works!</h1>
  <p>This is <code>index.html</code>, served by Nginx.</p>
</body>
</html>vagrant@ansible-host:~$ 
```

C'est le contenu du fichier `index.html` qui remplace celui livr√© par d√©faut avec Nginx.

#### Playbook pour installer NodeJS

Cr√©er un dossier `nodejs` et s'y placer :

```
mkdir nodejs
cd nodejs
```

Editer un nouveau playbook : `nano debian-nodejs.yaml` avec ce contenu :

```
---
- name: Configure webserver with nginx
  hosts: webservers
  become: True
  become_method: sudo
  vars:
    node_apps_location: /usr/local/opt/node
  tasks:
     - name: install nodejs
       apt:
         name: nodejs
         update_cache: yes
```

Ce fichier introduit une nouvelle notion, celle de variables (qu'on va utiliser un peu plus loin).

Ex√©cuter le playbook : `ansible-playbook debian-nodejs.yaml`

Cr√©er un nouveau sous-dossier `app` :

```
mkdir app
```

Editer un fichier contenant une app Node.js/Express : `nano app/index.js` avec ce contenu (r√©cup√©r√© du "Getting Started" de la doc ExpressJS) :

```javascript
const express = require('express')
const app = express()
const port = 3000

app.get('/', (req, res) => {
  res.send('Hello World!')
})

app.listen(port, () => {
  console.log(`Example app listening at http://localhost:${port}`)
})

```

Editer le `package.json` pour cette app : `nano app/package.json, avec ce contenu :

```json
{
  "name": "Express app",
  "dependencies": {
    "express": "^4.17.0"
  }
}
```

Ajouter ce bloc de t√¢ches √† la fin de `debian-nodejs.yaml`, r√©cup√©r√© depuis le tutoriel [D√©ployer un serveur Node.js sur CentOS](https://iac.goffinet.org/ansible-linux/deployer-un-serveur-nodejs-centos/) :

```
    - name: Ensure Node.js app folder exists.
      file:
        path: "{{ node_apps_location }}"
        state: directory
    - name: Copy example Node.js app to server.
      copy:
        src: app
        dest: "{{ node_apps_location }}"
    - name: Install app dependencies defined in package.json.
      npm:
        path: "{{ node_apps_location }}/app"
```

Ces trois nouvelles t√¢ches permettent :

* De v√©rifier si le dossier `/usr/local/opt/node` (valeur de la variable `node_apps_location`) existe, et de le cr√©er si n√©cessaire
* De copier tout le dossier `app` vers ce dossier
* D'installer les d√©pendances avec NPM, en se pla√ßant dans ce dossier

Relancer le playbook : `ansible-playbook debian-nodejs.yaml`

* ajouter package.json
* installer npm (transformer valeur derri√®re name en tableau)
* Fa√ßon naive de lancer node

    - name: Start example Node.js app.
      command: "node {{ node_apps_location }}/app/index.j>

marche pas : voir post stack overflow 
--> tentative avec forever (marche pas non plus, probablement deprecation de forever_list)
--> marche avec pm2 (suppression avant relancement)
--> `curl http://192.168.56.10:3000/` √† la fin

Attention le pm2 delete plante, que ce soit `pm2 delete node-app` ou `pm2 delete all`

